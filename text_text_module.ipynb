{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "# Check if GPU is available and move the model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Wrap the model with DataParallel\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Let's use {torch.cuda.device_count()} GPUs!\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "def generate_and_save_embeddings(dataloader):\n",
    "    \"\"\"\n",
    "    Process a dataloader containing batches of sentence and path pairs to generate embeddings and save them to specified paths.\n",
    "\n",
    "    Args:\n",
    "    dataloader (DataLoader): A DataLoader object that yields batches of tuples (sentences, save_paths).\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Temporarily set all the requires_grad flag to false\n",
    "        for batch in tqdm(dataloader, desc=\"Processing batches\"):\n",
    "            sentences, save_paths = batch\n",
    "            # Encode the sentences to get token ids and attention masks\n",
    "            inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "\n",
    "            # Pass the inputs to the model and get the last hidden state\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state\n",
    "\n",
    "            # Average the embeddings over the sequence length to get a single vector for each sentence\n",
    "            sentence_embeddings = embeddings.mean(dim=1)\n",
    "\n",
    "            # Process each sentence embedding in the batch\n",
    "            for i, sentence_embedding in enumerate(sentence_embeddings):\n",
    "                # Move embedding back to CPU for saving\n",
    "                sentence_embedding = sentence_embedding.cpu()\n",
    "\n",
    "                # Ensure the directory exists\n",
    "                dir_path = os.path.dirname(save_paths[i])\n",
    "                if not os.path.exists(dir_path):\n",
    "                    os.makedirs(dir_path)\n",
    "\n",
    "                # Save the embeddings as a tensor to the specified path\n",
    "                torch.save(sentence_embedding, f'{save_paths[i]}.pt')\n",
    "\n",
    "                # To save as a numpy array, convert it first\n",
    "                sentence_embedding_np = sentence_embedding.numpy()\n",
    "                np.save(f'{save_paths[i]}.npy', sentence_embedding_np)\n",
    "\n",
    "# Read data for DataLoader\n",
    "with open(\"/local/home/hhamidi/t_dif/diffusers/examples/text_to_image/dataset/sentence.txt\", \"r\") as f:\n",
    "    sentences = f.read().splitlines()\n",
    "\n",
    "with open(\"/local/home/hhamidi/t_dif/diffusers/examples/text_to_image/dataset/img_path.txt\", \"r\") as f:\n",
    "    img_paths = f.read().splitlines()\n",
    "\n",
    "base_path= \"/local/home/hhamidi/t_dif/diffusers/examples/text_to_image/dataset/\"\n",
    "img_paths = [ base_path + item for item in base_path]\n",
    "# Combine sentences and image paths into a list of tuples\n",
    "data = list(zip(sentences, img_paths))\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(data, batch_size=2 * torch.cuda.device_count(), shuffle=False)  # Adjust batch_size as needed based on the number of GPUs\n",
    "\n",
    "# Call the function\n",
    "generate_and_save_embeddings(dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
